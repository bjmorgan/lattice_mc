{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lattice_mc\n",
    "`lattice_mc` is Python module for running (kinetic) lattice-gas Monte Carlo simulations. Simple lattices can be constructed programmatically (presently square, honeycomb, and cubic lattices). Arbitrary lattices can be generated from files that define the lattice sites and their connectivity. The algorithms used and interaction models are described in [\\[1\\]](#ref1). Calculated properties include tracer and &ldquo;jump&rdquo; diffusion coefficients; where the latter is proportional to the mobility (and hence the conductivity for charged particles) [\\[2\\]](#ref2); and tracer (single particle) and collective correlation factors, $f$ and $f_\\mathrm{I}$ [\\[3\\]](#ref3). The simplest interaction model is for &ldquo;non-interacting&rdquo; particles, where the only restriction is volume exclusion (two particles cannot simultaneously occupy a single site) [\\[4\\]](#ref4). Additional interaction models include nearest-neighbour repulsion and on-site energies for inequivalent sites.\n",
    " \n",
    "## Contents:\n",
    "\n",
    "- Simulating the Diffusion of a Single Particle on a Square Lattice.\n",
    "- Improved Averages using multiprocessing.\n",
    "- Calculating correlation factors as a function of particle number.\n",
    "- Interacting Particles:\n",
    "    - Nearest-Neighbour Repulsion.\n",
    "        - Example - The Effect of Nearest-Neighbour repulsion on a Honeycomb Lattice.\n",
    "    - On-site Energies.\n",
    "        - Example - The Effect of Site Inequivalence on a Honeycomb Lattice\n",
    "- Defining a Lattice from a Sites File\n",
    "    - Example: Lattice-Gas Monte Carlo Simulation on a Garnet Lattice.\n",
    "- Running simulations for a set time, instead of a set number of jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lattice_mc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from math import sqrt, fabs\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global variables controlling simulation parallelisation and convergence.\n",
    "\n",
    "# NPROCS sets the number of processors available for running parallel simulations\n",
    "NPROCS = 32\n",
    "\n",
    "# NSAMPLES sets the number of identical simulations averaged over for each data point\n",
    "NSAMPLES = 500\n",
    "\n",
    "# !!! Large NSAMPLES and small NPROCS will make this notebook very slow to run !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define temperature scale\n",
    "kT = lattice_mc.global_vars.kT # default setting is T=298 K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the diffusion of a single particle on a square lattice\n",
    "The `run_simulation` function sets up a simulation with a 6&times;6 square lattice, using one of the functions from `lattice_mc.init_lattice`). The simulation parameters are:    \n",
    "lattice spacing, $a=1$.  \n",
    "1 atom.  \n",
    "10000 jumps.  \n",
    "Particles are non-interacting apart from volume exclusion, because we have not explicitly defined additional interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lattice_mc.simulation.Simulation object at 0x7fc900c466a0>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def run_simulation():\n",
    "    a, b = 6, 6 # creates 4x4x4=64 sites\n",
    "    spacing = 1.0\n",
    "    n_atoms = 1\n",
    "    n_jumps = 10000\n",
    "    s = lattice_mc.Simulation()\n",
    "    s.lattice = lattice_mc.init_lattice.square_lattice( a, b, spacing )\n",
    "    s.set_number_of_atoms( n_atoms )\n",
    "    s.set_number_of_jumps( n_jumps )\n",
    "    s.run()\n",
    "    return s\n",
    "    \n",
    "s = run_simulation()\n",
    "print( s )\n",
    "print( s.has_run )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having run a simulation we can access the following information as properties of the Simulation object:\n",
    "\n",
    "| Property.                     | symbol          | syntax.                                       |\n",
    "|-------------------------------|-----------------|-----------------------------------------------|\n",
    "| has the simulation run?       | N/A             | `Simulation.has_run`                          |\n",
    "| correlation factor            | $f$             | `Simulation.tracer_correlation`               | \n",
    "| collective correlation factor | $f_\\mathrm{I}$  | `Simulation.collective_correlation`           |\n",
    "| tracer diffusion coefficient  | $D^*$           | `Simulation.tracer_diffusion_coefficient`     |\n",
    "| &ldquo;jump&rdquo; diffusion coefficient  | $D_\\mathrm{J}$  | `Simulation.collective_diffusion_coefficient` |\n",
    "| average site occupations      | occ($\\alpha$)   | `Simulation.average_site_occupations`         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f   = 0.6074\n",
      "f_I = 0.6074\n",
      "D*  = 4.173e+12\n",
      "D_J = 4.173e+12\n",
      "occ(L) = 1.000000\n"
     ]
    }
   ],
   "source": [
    "s = run_simulation()\n",
    "print( \"f   = {}\".format( s.tracer_correlation ) )\n",
    "print( \"f_I = {}\".format( s.collective_correlation ) )\n",
    "print( \"D*  = {:.3e}\".format( s.tracer_diffusion_coefficient ) )\n",
    "print( \"D_J = {:.3e}\".format( s.collective_diffusion_coefficient ) )\n",
    "# Simulation.average_site_occupations returns a dictionary\n",
    "for k, v in s.average_site_occupations.items():\n",
    "    print( \"occ({}) = {:f}\".format( k, v ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single particle (i.e. in the dilute non-interacting limit) the tracer correlation factor and collective correlation factor should both be equal to 1. This is unlikely here because a single short simulation does not give good statistics.\n",
    "\n",
    "## Improved averages using multiprocessing\n",
    "\n",
    "Better converged results are achieved with longer simulations, or by running multiple equivalent simulations and taking averages. On a multiprocessor machine, this parallelisation over simulations can be done by wrapping `run_simulation()` in a second function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulation_wrapper(_):\n",
    "    s = run_simulation()\n",
    "    return s.tracer_correlation, s.collective_correlation, s.tracer_diffusion_coefficient, s.collective_diffusion_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_simulations( simulation_function, nproc, n_samples ):\n",
    "    pool = multiprocessing.Pool( processes=nproc )\n",
    "    calc_pool = ( range( n_samples ) )\n",
    "    f_sampled = np.array( pool.map( simulation_function, calc_pool ) )\n",
    "    f = sum( f_sampled ) / n_samples\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f   = 0.9304972\n",
      "f_I = 0.9304972\n",
      "D*  = 6.197e+12\n",
      "D_J = 6.197e+12\n"
     ]
    }
   ],
   "source": [
    "data = run_simulations( simulation_wrapper, nproc=NPROCS, n_samples=NSAMPLES )\n",
    "print( \"f   = {}\".format( data[0] ) )\n",
    "print( \"f_I = {}\".format( data[1] ) )\n",
    "print( \"D*  = {:.3e}\".format( data[2] ) )\n",
    "print( \"D_J = {:.3e}\".format( data[3] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating correlation factors as a function of particle number\n",
    "\n",
    "This example calculates the single-particle correlation factor, $f$, and collective correlation factor, $f_I$, as a function of particle concentration, for a honeycomb lattice. Here we create a lookup table for the jump probabilities, using `Simulation.setup_lookup_table`, to speed up the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def honeycomb_lattice_correlation( n_atoms ):\n",
    "    a, b = 4, 3\n",
    "    spacing = 1.0\n",
    "    n_jumps = 10000 \n",
    "    s = lattice_mc.Simulation()\n",
    "    s.lattice = lattice_mc.init_lattice.honeycomb_lattice( a, b, spacing )\n",
    "    s.set_number_of_atoms( n_atoms )\n",
    "    s.set_number_of_jumps( n_jumps )\n",
    "    s.setup_lookup_table() # Create a lookup table for jump probabilities to speed up the simulation\n",
    "    s.run()\n",
    "    return s.tracer_correlation, s.collective_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# redefine run_simulations so that it now passes n_atoms through to the simulation function\n",
    "def run_simulations( n_atoms, simulation_function, nproc, n_samples ):\n",
    "    pool = multiprocessing.Pool( processes=nproc )\n",
    "    f_data = []\n",
    "    for n in n_atoms:\n",
    "        calc_pool = ( n for i in range( n_samples ) )\n",
    "        f_sampled = np.array( pool.map( simulation_function, calc_pool ) )\n",
    "        f = sum( f_sampled ) / n_samples\n",
    "        f_data.append( [ n, *f ] )\n",
    "    return f_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_atoms = np.array( [ 1, 8, 16, 24, 32, 40, 47 ] )\n",
    "results = run_simulations( n_atoms, honeycomb_lattice_correlation, nproc=NPROCS, n_samples=NSAMPLES )\n",
    "data = pd.DataFrame( np.row_stack( results ), columns=[ 'n', 'f', 'f_I' ] )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.plot( data.n, data.f,   'o-', label='f'  )\n",
    "plt.plot( data.n, data.f_I, 'o-', label='f_I')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# The tracer correlation factor in the single vacancy limit is 0.33333 [Friauf J. Appl. Phys. 33, 494 (1962)]\n",
    "print( \"f_v = {:.4f} (exact result = 0.3333)\".format( data.f.values[-1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collective correlation factor, $f_I$ should equal 1 at all particle concentrations, but has much worse statistics than the single particle (tracer) correlation factor. This is because the single particle correlation factor calculation includes an average over all particles in the simulation, whereas the collective correlation factor depends on a *sum* over all particles, and does not have this additional averaging. (cf. the comparison between simulated diffusion coefficients and ionic conductivities in <a href=\"#ref1\">\\[5\\]</a>.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting Particles\n",
    "\n",
    "For non-interacting particles, all allowed particle jumps have equal probability. Introducing interactions changes the relative probabilities of each jump according to the corresponding change in total energy:\n",
    "\n",
    "\\begin{equation}\n",
    "  P_i \\propto \n",
    "  \\begin{cases}\n",
    "    \\mathrm{exp}\\left(\\frac{\\Delta E_i}{kT}\\right),& \\mathrm{if}\\,\\,\\Delta E_i > 0 \\\\\n",
    "    1,                                             & \\mathrm{otherwise.}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "### Nearest-neighbour repulsion\n",
    "\n",
    "The energy of any configuration of occupied sites, $j$ is given by\n",
    "\\begin{equation}\n",
    "  E = \\sum_j n_j^\\mathrm{nn}E_\\mathrm{nn},\n",
    "\\end{equation}\n",
    "where $n^\\mathrm{nn}_j$ is the number of occupied nearest neighbour sites for (occupied) site $j$.\n",
    "\n",
    "#### Example - The Effect of Nearest-Neighbour repulsion on a Honeycomb Lattice\n",
    "\n",
    "Nearest neighbour repulsion energies $E_\\mathrm{nn}$ are set using \n",
    "```python\n",
    "Simulation.set_nn_energy( <energy> ).  \n",
    "```\n",
    "In this example, the lattice is constructed using the optional argument\n",
    "```python\n",
    "alternating_sites=True\n",
    "```\n",
    "which divides the lattice into alternating sites labelled A and B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def honeycomb_lattice_correlation_nn( n_atoms, nn_repulsion ):\n",
    "    a, b = 4, 3\n",
    "    spacing = 1.0\n",
    "    n_jumps = 10000 # much longer simulations needed for reasonable statistics.\n",
    "    n_equilibration_jumps = 100 # need to include equilibration jumps.\n",
    "    s = lattice_mc.Simulation()\n",
    "    # Setting alternating_sites=True assigns site labels 'A' and 'B' to alternating sites on the lattice.\n",
    "    s.lattice = lattice_mc.init_lattice.honeycomb_lattice( a, b, spacing, alternating_sites=True )\n",
    "    s.set_number_of_atoms( n_atoms )\n",
    "    s.set_number_of_jumps( n_jumps )\n",
    "    s.set_number_of_equilibration_jumps( n_equilibration_jumps )\n",
    "    s.set_nn_energy( nn_repulsion * kT )\n",
    "    s.setup_lookup_table() # Create a lookup table for jump probabilities to speed up the simulation\n",
    "    s.run()\n",
    "    # Order parameter to quantify the preference for either site A or site B.\n",
    "    # Sites A and B are equivalent by symmetry, so we take the absolute difference in populations.\n",
    "    order_parameter = fabs( s.average_site_occupations['A'] - s.average_site_occupations['B'] ) / 24\n",
    "    return s.tracer_correlation, s.collective_correlation, order_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_simulations( n_atoms, nn_energy, simulation_function, nproc, n_samples ):\n",
    "    pool = multiprocessing.Pool( processes=nproc )\n",
    "    f_data = []\n",
    "    for n in n_atoms:\n",
    "        for nn in nn_energy:\n",
    "            calc_pool = ( ( n, nn ) for i in range( n_samples ) )\n",
    "            f_sampled = np.array( pool.starmap( simulation_function, calc_pool ) )\n",
    "            f = sum( f_sampled ) / n_samples\n",
    "            f_data.append( [ n, nn, *f ] )\n",
    "    return f_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_atoms = np.array( [ 1, 8, 16, 24, 32, 40, 47 ] )\n",
    "nn_energy = [ 0.0, 1.0, 2.0, 3.0, 4.0 ]\n",
    "results = run_simulations( n_atoms, nn_energy, honeycomb_lattice_correlation_nn, nproc=NPROCS, n_samples=NSAMPLES )\n",
    "data = pd.DataFrame( np.row_stack( results ), columns = [ 'n_atoms', 'E_nn', 'f', 'f_I', 'order_parameter' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nn in nn_energy:\n",
    "    nn_data=data[data.E_nn==nn]\n",
    "    plt.plot( nn_data.n_atoms, nn_data.f, 'o-', label=\"E_nn = {}\".format(nn) )\n",
    "    plt.legend()\n",
    "    plt.title( 'tracer correlation factor' )\n",
    "plt.show()\n",
    "\n",
    "for nn in nn_energy:\n",
    "    nn_data=data[data.E_nn==nn]\n",
    "    plt.plot( nn_data.n_atoms, nn_data.f_I, 'o-', label=\"E_nn = {}\".format(nn) )\n",
    "    plt.legend()\n",
    "    plt.title( 'collective correlation factor' )\n",
    "plt.show()\n",
    "\n",
    "for nn in nn_energy:\n",
    "    nn_data=data[data.E_nn==nn]\n",
    "    plt.plot( nn_data.n_atoms, nn_data.order_parameter, 'o-', label=\"E_nn = {}\".format(nn) )\n",
    "    plt.legend()\n",
    "    plt.title( 'order parameter' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the nearest-neighbour repulsion energy increases, both $f$ and $f_I$ are decreased as the lattice occupancy approaches 50% (cf. results published in <a href=\"#ref1\">\\[6\\]</a>). The order parameter plot shows that this is associated with a preference for all the mobile particles to order on one subset of alternating sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On-site Energies\n",
    "\n",
    "The on-site contribution to the energy is given by\n",
    "\\begin{equation}\n",
    "  E = \\sum_j E_\\mathrm{site}^j.\n",
    "\\end{equation}\n",
    "Within the code, sites are distinguished using labels, and different on-site energies can be set for each site label.\n",
    "\n",
    "#### Example - The Effect of Site Inequivalence on a Honeycomb Lattice\n",
    "\n",
    "Site occupation energied $E_\\mathrm{site}$  are set using `Simulation.set_site_energies( <dict> )`.  \n",
    "In this example, the lattice is constructed using the optional argument `alternating_sites=True`, which divides the lattice into alternating sites labelled A and B. The site energies are then set with\n",
    "```python\n",
    "s.set_site_energies( { 'A' : 0.0, 'B' : site_delta_E * kT } )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def honeycomb_lattice_correlation_si( n_atoms, site_delta_E ):\n",
    "    a, b = 4, 3\n",
    "    spacing = 1.0\n",
    "    n_jumps = 10000 # much longer simulations needed for reasonable statistics.\n",
    "    n_equilibration_jumps = 100 # need to include equilibration jumps\n",
    "    s = lattice_mc.Simulation()\n",
    "    s.lattice = lattice_mc.init_lattice.honeycomb_lattice( a, b, spacing, alternating_sites=True )\n",
    "    s.set_number_of_atoms( n_atoms )\n",
    "    s.set_number_of_jumps( n_jumps )\n",
    "    s.set_number_of_equilibration_jumps( n_equilibration_jumps )\n",
    "    s.set_site_energies( { 'A' : 0.0, 'B' : site_delta_E * kT } )\n",
    "    s.setup_lookup_table() # Create a lookup table for jump probabilities to speed up the simulation\n",
    "    s.run()\n",
    "    a_site_preference = ( s.average_site_occupations['A'] - s.average_site_occupations['B'] ) / 24\n",
    "    return s.tracer_correlation, s.collective_correlation, a_site_preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_simulations( n_atoms, site_delta_E, simulation_function, nproc, n_samples ):\n",
    "    pool = multiprocessing.Pool( processes=nproc )\n",
    "    f_data = []\n",
    "    for n in n_atoms:\n",
    "        for dE in site_delta_E:\n",
    "            calc_pool = ( ( n, dE ) for i in range( n_samples ) )\n",
    "            f_sampled = np.array( pool.starmap( simulation_function, calc_pool ) )\n",
    "            f = sum( f_sampled ) / n_samples\n",
    "            f_data.append( [ n, dE, *f ] )\n",
    "    return f_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_atoms = np.array( [ 1, 8, 16, 24, 32, 40, 47 ] )\n",
    "site_delta_E = [ 0.0, 1.0, 2.0, 3.0, 4.0 ]\n",
    "results = run_simulations( n_atoms, nn_energy, honeycomb_lattice_correlation_nn, nproc=NPROCS, n_samples=NSAMPLES )\n",
    "data = pd.DataFrame( np.row_stack( results ), columns = [ 'n_atoms', 'delta_E_site', 'f', 'f_I', 'A site preference' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dE in site_delta_E:\n",
    "    nn_data=data[data.delta_E_site==dE]\n",
    "    plt.plot( nn_data.n_atoms, nn_data.f, 'o-', label=nn )\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for dE in site_delta_E:\n",
    "    nn_data=data[data.delta_E_site==dE]\n",
    "    plt.plot( nn_data.n_atoms, nn_data.f_I, 'o-', label=nn )\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for dE in site_delta_E:\n",
    "    nn_data=data[data.delta_E_site==dE]\n",
    "    plt.plot( nn_data.n_atoms, nn_data['A site preference'], 'o-', label=nn )\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the A and B sites inequivalent, by introducing on-site energies, has a similar effect to nearest-neighbour repulsion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Add titles and axis labels to figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Lattice from a Sites File\n",
    "\n",
    "All the examples so far have used one of the built-in lattice generation routines. Arbitrary lattices can be constructed using \n",
    "```python\n",
    "Simulation.define_lattice_from_file( <filename>, <cell lengths> )\n",
    "```\n",
    "A sites file starts with the number of sites, and then has the same number of blocks with the format:\n",
    "```\n",
    "site: <integer>\n",
    "center: <float> <float> <float>\n",
    "neighbours: <integer> Ã— m\n",
    "label: <string>\n",
    "(optional) energy: <float>\n",
    "```\n",
    "\n",
    "So the top of a sites file might look like\n",
    "```\n",
    "576\n",
    "\n",
    "site: 5\n",
    "centre: 21.4669 -1.37099999975e-05 6.133405\n",
    "neighbours: -2 -3 -4 -309\n",
    "label: T\n",
    "\n",
    "site: 10\n",
    "centre: 21.4669 -1.37099999975e-05 30.667\n",
    "neighbours: -6 -7 -8 -311\n",
    "label: T\n",
    "```\n",
    "\n",
    "`site:` assigns an integer to each site that is used to identify it. Each site must have a unique identifying integer.  \n",
    "`centre:` is the coordinate of the lattice site.  \n",
    "`neighbours:` is the list of integers identifying the sites neighbouring this site.  \n",
    "`label:` identifies this site as belonging to a group of sites.  \n",
    "`energy:` sets the site energy (optional).\n",
    "\n",
    "The `centre` and `neighbours` entries can be British or American English spellings (`centre`|`center`) and (`neighbours`|`neighbors`).\n",
    "\n",
    "The program does not check that your cell paramateres are consistent with the coordinates provided in the site file. Instead, when the lattice is constructed, periodic boundary conditions are applied, and site coordinates lying outside the (orthorhombic) cell are mapped to an equivalent position inside the cell.\n",
    "\n",
    "### Example: Lattice-Gas Monte Carlo Simulation on a Garnet Lattice\n",
    "\n",
    "cf. Ref. [\\[1\\]](#ref1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def garnet_lattice_correlation( n_atoms ):\n",
    "    n_jumps = 10000\n",
    "    n_equilibration_jumps = 100\n",
    "    s = lattice_mc.Simulation()\n",
    "    s.define_lattice_from_file( 'llzo_lattice_site_list.dat', [ 49.0672361, 49.0672361, 49.0672361 ] )\n",
    "    s.set_number_of_atoms( n_atoms )\n",
    "    s.set_number_of_jumps( n_jumps )\n",
    "    s.set_number_of_equilibration_jumps( n_equilibration_jumps )\n",
    "    s.setup_lookup_table() # Create a lookup table for jump probabilities to speed up the simulation\n",
    "    s.run()\n",
    "    return s.tracer_correlation, s.collective_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_simulations( n_atoms, simulation_function, nproc, n_samples ):\n",
    "    pool = multiprocessing.Pool( processes=nproc )\n",
    "    f_data = []\n",
    "    for n in n_atoms:\n",
    "        calc_pool = ( n for i in range( n_samples ) )\n",
    "        f_sampled = np.array( pool.map( simulation_function, calc_pool ) )\n",
    "        f = sum( f_sampled ) / n_samples\n",
    "        f_data.append( [ n, *f ] )\n",
    "    return f_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_atoms = np.array( [ 1, 96, 192, 288, 384, 480, 575 ] )\n",
    "results = run_simulations( n_atoms, garnet_lattice_correlation, nproc=NPROCS, n_samples=NSAMPLES )\n",
    "data = pd.DataFrame( np.row_stack( results ), columns=[ 'n', 'f', 'f_I' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.plot( data.n, data.f,   'o-', label='f'  )\n",
    "plt.plot( data.n, data.f_I, 'o-', label='f_I')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running simulations for a set time, instead of a set number of jumps\n",
    "\n",
    "Call the Simulation `.run()` method with the optional argument `for_time=<simulation time in seconds>`.  \n",
    "\n",
    "e.g.\n",
    "\n",
    "```python\n",
    "s = lattice_mc.Simulation()\n",
    "```\n",
    "&hellip;\n",
    "```\n",
    "s.run( for_time=1.0 ) # run for 1 second.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<span id='ref1'>[1] B. J. Morgan, In Preparation.</span>  \n",
    "<span id='ref2'>[2] A. Van der Ven *et al.* [*Acc. Chem. Res.* **46**, 1216 (2013)](https://dx.doi.org/10.1021/ar200329r)</span>  \n",
    "<span id='ref3'>[3] G. E. Murch [*Sol. Stat. Ionics* **7**, 177 (1982)](https://dx.doi.org/10.1016/0167-2738%2882%2990050-9)</span>  \n",
    "<span id='ref4'>[4] R. Kutner [*Phys. Lett.* **81A**, 239 (1981)](https://dx.doi.org/10.1016/0375-9601%2881%2990251-6)\n",
    "</span>  \n",
    "<span id='ref5'>\\[5\\] Morgan and Madden, [*J. Phys. Condens. Matter* **24**, 275303 (2012)](http://www.iopscience.iop.org/article/10.1088/0953-8984/24/27/275303/)</span>.  \n",
    "<span id='ref6'> \\[6\\] G. E. Murch & R. J. Thorn, [Phil. Mag. **36** 529 (1977)](http://dx.doi.org/10.1080/14786437708239737)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
